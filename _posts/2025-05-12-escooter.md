---
layout: post  
author: Lasse P. S. H.  
title: "You Only Train a 100 different YOLO Models"  
---

# You Only Train a 100 different YOLO Models

Understanding urban micromobility behavior—particularly the use of E-scooters—requires scalable and efficient detection methods. In this project, we explore the fine-tuning of YOLOv11 to detect E-scooters in public video footage from three Swiss cities: Zurich, Basel, and Bern.

## Data Collection

Video data were collected at two distinct sites in each of the three cities. We sampled frames every 10 seconds, resulting in an impressive **2136 hours** of footage and a total of **769,194 frames** for potential analysis.

<div style="display:flex; justify-content:space-around;">
  <img src="/img/zurich.png" width="30%" />
  <img src="/img/basel.png" width="30%" />
  <img src="/img/bern.png" width="30%" />
</div>

We manually annotated **78,770** of these frames to detect E-scooters, using [CVAT](https://github.com/opencv/cvat) for bounding box labeling. In total, we created **755 annotations**. To mitigate false positives, we added **266 background frames** (frames without E-scooters), roughly 30% per location.

## The Model

We used the **Ultralytics YOLOv11** object detection model, which comes with **56.9 million parameters**. The model was pre-trained on a broad dataset and then fine-tuned on our custom dataset to focus on detecting a single class: E-scooters.

![Training](img/training.png)  
*Figure: Training was conducted on an NVIDIA RTX A5000 GPU using 1280×1280 images and a batch size of 8. Early stopping occurred at epoch 677. We applied horizontal flipping and scale augmentations, and enabled mixed precision training for efficiency.*

## Evaluation & Results

After training, we used the model to generate predictions on new video frames. We retained predictions with a confidence score above 0.5, resulting in **11,312 frames**.

Each prediction was further annotated manually with behavioral attributes:
- Helmet use
- Dual use (e.g., two riders on one scooter)
- Phone use
- Misuse of infrastructure
- Wrong direction

We filtered out false positives, yielding a **ROC AUC of 0.71**. After filtering, **5,470** valid observations remained.

**Performance Metrics**:
- **Recall**: 0.93 (excellent sensitivity to true positives)
- **F1 score**: 0.76 (good balance of precision and recall)

## Usage Patterns

To analyze E-scooter activity over time, we extracted timestamps from each frame using OCR. This allowed us to measure usage by time of day and day of week.

![Scooters per hour](img/obs_per_hour.png)  
*Figure: Average count of E-scooters detected per hour of the day.*

![Weekly pattern](img/week_hour.png)  
*Figure: Weekly distribution of E-scooter detections.*

---

This study shows that even with limited training data and a focused annotation strategy, modern object detection models like YOLOv11 can be effectively fine-tuned for niche use cases like E-scooter monitoring. With strong performance metrics and temporal analysis, this pipeline offers a scalable approach to understanding urban mobility behavior.